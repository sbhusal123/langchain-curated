# Output Parsing, Structured Output


# 1. Structured Output

- Enforces predefined schema for response from LLM.

- Useful in cases where we need models output in specific JSON format.

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_ollama import ChatOllama

from pydantic import BaseModel, Field

class ResponseFormatter(BaseModel):
    joke:str = Field(..., alias="Output Joke")
    topic: str=Field(..., alias="Topic of Joke")


# specify output model
chat_ollama = ChatOllama(model="llama3:latest").with_structured_output(ResponseFormatter)

res_chat_ollama = chat_ollama.invoke("Tell me a joke about chicken")

print(res_chat_ollama)
# joke='Why did the chicken go to therapy?' topic='chicken'

# res_chat_ollama.joke
# res_chat_ollama.topic
```

## 2. Output Parsing:

Sample AIMessage -> Text String Parsing

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_ollama import ChatOllama

from langchain_core.messages import AIMessage, SystemMessage, HumanMessage

from langchain_core.output_parsers import StrOutputParser

chat_ollama = ChatOllama(model="llama3:latest")

chat_prompt_template = ChatPromptTemplate.from_messages([
    SystemMessage("You are a helpful assistant."),
    HumanMessage("Tell me a joke about {topic}")
])

output = StrOutputParser()

chain = chat_prompt_template | chat_ollama | output

res = chain.invoke({"topic": "chicken"})

print(res)
# Output: Why did the chicken join a band? Because it had the drumsticks.

print(type(res))
# Output: <class 'str'>
```

Note that, ``chat_ollama.invoke(...)`` returns ``AIMessage`` which is fed to output ``StrOutputParser`` which returns a string.

**Avaibale parser classes:**
```python
from langchain_core.output_parsers import (
    StrOutputParser, JsonOutputParser, CommaSeparatedListOutputParser, 
    ListOutputParser, PydanticOutputParser
)
```
