# Simple RAG - Embed Docs

**Concepts:**
- ``langchain_community.document_loaders`` usage to load a documents.
- ``langchain_text_splitters`` to split a loaded document.
- Chroma to create embedings.

Here, we have a source text ``readme.txt``.
- Load it and split it with `.` separator, chunk size is 100 and overlap size is 10.
- Create a embeding from the loaded docs.


```python
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import CharacterTextSplitter

# Loading and Splitting Text
raw_text = TextLoader('./readme.txt').load()
splitter  = CharacterTextSplitter(separator='.', chunk_size=100, chunk_overlap=10)
docs = splitter.split_documents(raw_text)


# construct embeddings
from langchain_chroma.vectorstores import Chroma
from langchain_ollama.embeddings import OllamaEmbeddings


embeding = OllamaEmbeddings(model='nomic-embed-text:latest')
db = Chroma.from_documents(docs, embeding)


# query for similarity
query = "How about refund policy?"
result = db.similarity_search(query, k=1)
print(result)


Here, we load a text from readme.txt, split it into sub documents.
Then a embeding is created out of it and stored in a chroma db.
